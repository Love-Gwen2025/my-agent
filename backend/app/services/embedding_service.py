"""
Embedding æœåŠ¡ - æ”¯æŒæœ¬åœ°æ¨¡å‹å’Œè¿œç¨‹ API

æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
1. æœ¬åœ°æ¨¡å‹ (bge-small-zh-v1.5) - å…è´¹ã€éšç§å®‰å…¨ã€æ— ç½‘ç»œå»¶è¿Ÿ
2. è¿œç¨‹ API (OpenAI/DeepSeek) - æ•ˆæœå¥½ï¼Œéœ€è¦ API Key
"""

from typing import Any

from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from app.core.settings import Settings
from app.models.message_embedding import MessageEmbedding


class EmbeddingService:
    """
    1. ç”Ÿæˆæ–‡æœ¬ embedding
    2. å­˜å‚¨åˆ° pgvector
    3. è¯­ä¹‰æ£€ç´¢ç›¸å…³æ¶ˆæ¯
    """

    def __init__(self, settings: Settings):
        self.settings = settings
        self.dimension = settings.ai_embedding_dimension
        self._model = None
        self._embeddings = None

        # æ ¹æ®é…ç½®é€‰æ‹©æ¨¡å‹ç±»å‹
        self.use_local = settings.ai_embedding_provider == "local"

    def _get_local_model(self):
        """
        å»¶è¿ŸåŠ è½½æœ¬åœ° Embedding æ¨¡å‹ (ä½¿ç”¨ fastembedï¼Œæ¯” sentence-transformers æ›´è½»é‡)
        fastembed ä½¿ç”¨ ONNX Runtimeï¼Œæ— éœ€ PyTorchï¼Œé•œåƒå¤§å°ä» 11GB é™è‡³ ~500MB
        """
        if self._model is None:
            from fastembed import TextEmbedding

            model_name = self.settings.ai_embedding_model
            print(f"ğŸ“¥ Loading local embedding model (fastembed): {model_name}")
            # fastembed ä¼šè‡ªåŠ¨ä¸‹è½½å¹¶ç¼“å­˜æ¨¡å‹åˆ° ~/.cache/fastembed
            self._model = TextEmbedding(model_name=model_name)
            print(f"âœ… Model loaded successfully")

        return self._model

    def _get_remote_embeddings(self):
        """
        è·å–è¿œç¨‹ Embedding å®¢æˆ·ç«¯
        """
        if self._embeddings is None:
            from langchain_openai import OpenAIEmbeddings

            api_key = self.settings.ai_embedding_api_key or self.settings.ai_openai_api_key
            base_url = self.settings.ai_embedding_base_url or self.settings.ai_openai_base_url

            self._embeddings = OpenAIEmbeddings(
                model=self.settings.ai_embedding_model,
                api_key=api_key,
                base_url=base_url,
            )

        return self._embeddings

    async def embed_text(self, text: str) -> list[float]:
        """
        ç”Ÿæˆæ–‡æœ¬çš„ embedding å‘é‡
        """
        if self.use_local:
            model = self._get_local_model()
            # fastembed.embed() è¿”å›ç”Ÿæˆå™¨ï¼Œéœ€è¦è½¬æ¢ä¸º list å–ç¬¬ä¸€ä¸ªç»“æœ
            vectors = list(model.embed([text]))
            return vectors[0].tolist()
        else:
            embeddings = self._get_remote_embeddings()
            return await embeddings.aembed_query(text)

    async def embed_texts(self, texts: list[str]) -> list[list[float]]:
        """
        æ‰¹é‡ç”Ÿæˆ embedding
        """
        if self.use_local:
            model = self._get_local_model()
            # fastembed.embed() è¿”å›ç”Ÿæˆå™¨ï¼Œæ‰¹é‡è½¬æ¢ä¸ºåˆ—è¡¨
            vectors = list(model.embed(texts))
            return [v.tolist() for v in vectors]
        else:
            embeddings = self._get_remote_embeddings()
            return await embeddings.aembed_documents(texts)

    async def store_message_embedding(
        self,
        db: AsyncSession,
        message_id: int,
        conversation_id: int,
        user_id: int,
        role: str,
        content: str,
    ) -> MessageEmbedding:
        """
        ä¸ºæ¶ˆæ¯ç”Ÿæˆ embedding å¹¶å­˜å‚¨
        """
        # ç”Ÿæˆå‘é‡
        vector = await self.embed_text(content)

        # å­˜å‚¨
        embedding = MessageEmbedding(
            message_id=message_id,
            conversation_id=conversation_id,
            user_id=user_id,
            role=role,
            content=content,
            embedding=vector,
        )
        db.add(embedding)
        await db.commit()
        await db.refresh(embedding)
        return embedding

    async def search_similar(
        self,
        db: AsyncSession,
        query: str,
        conversation_id: int | None = None,
        top_k: int = 5,
        similarity_threshold: float = 0.0,
    ) -> list[dict[str, Any]]:
        """
        è¯­ä¹‰æ£€ç´¢ç›¸å…³æ¶ˆæ¯

        Args:
            db: æ•°æ®åº“ä¼šè¯
            query: æŸ¥è¯¢æ–‡æœ¬
            conversation_id: å¯é€‰çš„ä¼šè¯ ID è¿‡æ»¤
            top_k: è¿”å›æœ€ç›¸ä¼¼çš„ K æ¡ç»“æœ
            similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„ç»“æœå°†è¢«è¿‡æ»¤

        è¿”å›: [{"content": str, "role": str, "similarity": float}, ...]
        """
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_vector = await self.embed_text(query)

        # æ„å»ºæŸ¥è¯¢ - ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦
        if conversation_id:
            sql = text("""
                SELECT
                    content,
                    role,
                    1 - (embedding <=> :query_vec::vector) as similarity
                FROM t_message_embedding
                WHERE conversation_id = :conv_id
                ORDER BY embedding <=> :query_vec::vector
                LIMIT :limit
            """)
            params = {
                "query_vec": str(query_vector),
                "conv_id": conversation_id,
                "limit": top_k,
            }
        else:
            sql = text("""
                SELECT
                    content,
                    role,
                    1 - (embedding <=> :query_vec::vector) as similarity
                FROM t_message_embedding
                ORDER BY embedding <=> :query_vec::vector
                LIMIT :limit
            """)
            params = {
                "query_vec": str(query_vector),
                "limit": top_k,
            }

        result = await db.execute(sql, params)
        rows = result.fetchall()

        # è¿‡æ»¤ä½äºé˜ˆå€¼çš„ç»“æœ
        return [
            {"content": row.content, "role": row.role, "similarity": float(row.similarity)}
            for row in rows
            if float(row.similarity) >= similarity_threshold
        ]
