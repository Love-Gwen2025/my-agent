"""
ä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹ (Context Augmentation Node)

Chat Mode çš„å¹¶è¡Œæ£€ç´¢å±‚ï¼Œè´Ÿè´£ï¼š
1. è·å–å†å²å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆé€šè¿‡ RAG æ£€ç´¢ç›¸å…³å†å²ï¼‰
2. è·å–çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼ˆé€šè¿‡å‘é‡æ£€ç´¢ç›¸å…³æ–‡æ¡£ï¼‰

ä¸¤ä¸ªæ£€ç´¢å¹¶è¡Œæ‰§è¡Œï¼Œç»“æœåˆå¹¶åˆ° state ä¸­ä¾› chatbot ä½¿ç”¨ã€‚
"""

import asyncio
from typing import Any

from langchain_core.messages import HumanMessage
from loguru import logger

from app.utils.content import extract_text_content


async def get_history_context(
    query: str,
    embedding_service,
    db_session,
    conversation_id: int | None,
    top_k: int = 5,
    similarity_threshold: float = 0.6,
) -> str:
    """
    è·å–å†å²å¯¹è¯ä¸Šä¸‹æ–‡

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        embedding_service: Embedding æœåŠ¡å®ä¾‹
        db_session: æ•°æ®åº“ä¼šè¯
        conversation_id: ä¼šè¯ ID
        top_k: è¿”å›ç»“æœæ•°é‡
        similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼

    Returns:
        æ ¼å¼åŒ–çš„å†å²ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    """
    if not embedding_service or not db_session or not conversation_id:
        return ""

    try:
        results = await embedding_service.search_similar(
            db=db_session,
            query=query,
            conversation_id=conversation_id,
            top_k=top_k,
            similarity_threshold=similarity_threshold,
        )

        if not results:
            return ""

        # æ ¼å¼åŒ–ç»“æœ
        formatted = []
        for i, msg in enumerate(results, 1):
            role = "ç”¨æˆ·" if msg["role"] == "user" else "åŠ©æ‰‹"
            formatted.append(f"{i}. {role}: {msg['content']}")

        logger.info(f"ğŸ“œ History context: found {len(results)} relevant messages")
        return "ã€ç›¸å…³å†å²å¯¹è¯ã€‘\n" + "\n".join(formatted)

    except Exception as e:
        logger.error(f"Failed to get history context: {e}")
        return ""


async def get_kb_context(
    query: str,
    embedding_service,
    db_session,
    knowledge_base_ids: list[int],
    top_k: int = 5,
    similarity_threshold: float = 0.5,
    use_hybrid: bool = True,
) -> str:
    """
    è·å–çŸ¥è¯†åº“ä¸Šä¸‹æ–‡

    Args:
        query: ç”¨æˆ·æŸ¥è¯¢
        embedding_service: Embedding æœåŠ¡å®ä¾‹
        db_session: æ•°æ®åº“ä¼šè¯
        knowledge_base_ids: çŸ¥è¯†åº“ ID åˆ—è¡¨
        top_k: è¿”å›ç»“æœæ•°é‡
        similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
        use_hybrid: æ˜¯å¦ä½¿ç”¨æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + BM25ï¼‰

    Returns:
        æ ¼å¼åŒ–çš„çŸ¥è¯†åº“ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
    """
    if not embedding_service or not db_session or not knowledge_base_ids:
        return ""

    try:
        if use_hybrid:
            results = await embedding_service.hybrid_search_knowledge_base(
                db=db_session,
                query=query,
                knowledge_base_ids=knowledge_base_ids,
                top_k=top_k,
                similarity_threshold=similarity_threshold,
                mode="union",
            )
        else:
            results = await embedding_service.search_knowledge_base(
                db=db_session,
                query=query,
                knowledge_base_ids=knowledge_base_ids,
                top_k=top_k,
                similarity_threshold=similarity_threshold,
            )

        if not results:
            return ""

        # æ ¼å¼åŒ–ç»“æœ
        formatted = []
        for i, chunk in enumerate(results, 1):
            source = chunk.get("file_name", "æœªçŸ¥æ¥æº")
            content = chunk["content"]
            similarity = chunk.get("similarity", 0)
            formatted.append(f"{i}. [{source}] (ç›¸ä¼¼åº¦: {similarity:.2f})\n{content}")

        logger.info(f"ğŸ“š KB context: found {len(results)} relevant chunks")
        return "ã€çŸ¥è¯†åº“å‚è€ƒèµ„æ–™ã€‘\n" + "\n\n".join(formatted)

    except Exception as e:
        logger.error(f"Failed to get KB context: {e}")
        return ""


def create_context_node(settings):
    """
    åˆ›å»ºä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹

    è¯¥èŠ‚ç‚¹å¹¶è¡Œæ‰§è¡Œå†å²æ£€ç´¢å’ŒçŸ¥è¯†åº“æ£€ç´¢ï¼Œå°†ç»“æœåˆå¹¶åˆ° state ä¸­ã€‚

    Args:
        settings: åº”ç”¨é…ç½®

    Returns:
        èŠ‚ç‚¹å‡½æ•°
    """

    async def context_node(state: dict[str, Any]) -> dict[str, Any]:
        """
        ä¸Šä¸‹æ–‡å¢å¼ºèŠ‚ç‚¹ï¼šå¹¶è¡Œè·å–å†å²å’ŒçŸ¥è¯†åº“ä¸Šä¸‹æ–‡

        è¾“å…¥ state:
          - messages: æ¶ˆæ¯åˆ—è¡¨
          - embedding_service: Embedding æœåŠ¡ï¼ˆé€šè¿‡ config æ³¨å…¥ï¼‰
          - db_session: æ•°æ®åº“ä¼šè¯ï¼ˆé€šè¿‡ config æ³¨å…¥ï¼‰
          - conversation_id: ä¼šè¯ IDï¼ˆé€šè¿‡ config æ³¨å…¥ï¼‰
          - knowledge_base_ids: çŸ¥è¯†åº“ ID åˆ—è¡¨

        è¾“å‡º state:
          - history_context: å†å²å¯¹è¯ä¸Šä¸‹æ–‡
          - kb_context: çŸ¥è¯†åº“ä¸Šä¸‹æ–‡
        """
        messages = state.get("messages", [])

        # ä» state ä¸­è·å–æ³¨å…¥çš„ä¾èµ–
        embedding_service = state.get("_embedding_service")
        db_session = state.get("_db_session")
        conversation_id = state.get("_conversation_id")
        knowledge_base_ids = state.get("knowledge_base_ids", [])

        # æå–ç”¨æˆ·æŸ¥è¯¢
        query = ""
        for msg in reversed(messages):
            if isinstance(msg, HumanMessage):
                query = extract_text_content(msg.content)
                break

        if not query:
            logger.warning("No user query found for context retrieval")
            return {"history_context": "", "kb_context": ""}

        logger.info(f"ğŸ” Context retrieval for query: {query[:50]}...")

        # å¹¶è¡Œæ‰§è¡Œä¸¤ä¸ªæ£€ç´¢ä»»åŠ¡
        history_task = get_history_context(
            query=query,
            embedding_service=embedding_service,
            db_session=db_session,
            conversation_id=conversation_id,
            top_k=settings.rag_top_k,
            similarity_threshold=settings.rag_similarity_threshold,
        )

        kb_task = get_kb_context(
            query=query,
            embedding_service=embedding_service,
            db_session=db_session,
            knowledge_base_ids=knowledge_base_ids,
            top_k=settings.rag_top_k,
            similarity_threshold=settings.rag_similarity_threshold,
            use_hybrid=True,
        )

        # å¹¶è¡Œç­‰å¾…ç»“æœ
        history_context, kb_context = await asyncio.gather(history_task, kb_task)

        logger.info(
            f"âœ… Context retrieved: history={len(history_context)} chars, kb={len(kb_context)} chars"
        )

        return {
            "history_context": history_context,
            "kb_context": kb_context,
        }

    return context_node
