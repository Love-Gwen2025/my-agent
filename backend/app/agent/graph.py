"""
LangGraph Agent æ„å»ºæ¨¡å— (v4 - çŸ¥è¯†åº“é›†æˆæ¶æ„)

æ–°æ¶æ„æ”¯æŒä¸¤ç§æ¨¡å¼ï¼Œå‡é›†æˆçŸ¥è¯†åº“ RAGï¼š

1. æ™®é€šå¯¹è¯æ¨¡å¼ (mode="chat"):
   START â†’ router â†’ rewrite â†’ context_retrieval â†’ chatbot â†’ [tools â†’ chatbot]* â†’ END

   context_retrieval èŠ‚ç‚¹å¹¶è¡Œæ‰§è¡Œï¼š
   - è·å–å†å²å¯¹è¯ä¸Šä¸‹æ–‡
   - è·å–çŸ¥è¯†åº“ä¸Šä¸‹æ–‡

2. æ·±åº¦æœç´¢æ¨¡å¼ (mode="deep_search"):
   START â†’ router â†’ kb_precheck â†’ planning â†’ [search â†’ planning]* â†’ summary â†’ END

   kb_precheck èŠ‚ç‚¹ï¼š
   - åœ¨è§„åˆ’å‰æ£€ç´¢å†…éƒ¨çŸ¥è¯†åº“
   - å°†å·²çŸ¥ä¿¡æ¯æ³¨å…¥ referencesï¼Œé¿å…é‡å¤æœç´¢

æ”¯æŒï¼š
- checkpoint_id åˆ†æ”¯ï¼ˆæ—¶é—´æ—…è¡Œï¼‰
- å·¥å…·è‡ªä¸»è°ƒç”¨ï¼ˆæ¨¡å‹å†³å®šæ˜¯å¦è°ƒç”¨ï¼‰
- DeepSearch å¤šè½®æœç´¢è§„åˆ’
- çŸ¥è¯†åº“ RAG æ··åˆæ£€ç´¢
"""

from typing import Annotated, Any, Literal

from langchain_core.messages import AIMessage, AnyMessage, SystemMessage
from langchain_core.tools import BaseTool
from langchain_openai import ChatOpenAI
from langgraph.graph import END, StateGraph
from langgraph.graph.message import add_messages
from langgraph.prebuilt import ToolNode
from loguru import logger
from typing_extensions import TypedDict

from app.nodes.chatbot_node import create_chatbot_node
from app.nodes.context_node import create_context_node
from app.nodes.kb_precheck_node import create_kb_precheck_node
from app.nodes.planning_node import create_planning_node
from app.nodes.rewrite_node import create_rewrite_node
from app.nodes.search_node import create_search_node
from app.nodes.summary_node import create_summary_node

# ========== 1. å®šä¹‰ Agent çŠ¶æ€ ==========


class AgentState(TypedDict):
    """
    Agent çš„çŠ¶æ€å®šä¹‰ (v4 - çŸ¥è¯†åº“é›†æˆ)ã€‚

    Attributes:
        messages: å¯¹è¯æ¶ˆæ¯å†å²ï¼ˆä½¿ç”¨ add_messages reducer è‡ªåŠ¨è¿½åŠ ï¼‰
        mode: å¯¹è¯æ¨¡å¼ ("chat" | "deep_search")

        # çŸ¥è¯†åº“ç›¸å…³
        knowledge_base_ids: å¯ç”¨çš„çŸ¥è¯†åº“ ID åˆ—è¡¨
        history_context: å†å²å¯¹è¯ä¸Šä¸‹æ–‡ï¼ˆcontext_node è¾“å‡ºï¼‰
        kb_context: çŸ¥è¯†åº“ä¸Šä¸‹æ–‡ï¼ˆcontext_node / kb_precheck è¾“å‡ºï¼‰

        # DeepSearch ä¸“ç”¨å­—æ®µ
        question: ç”¨æˆ·åŸå§‹é—®é¢˜
        search_queries: å¾…æœç´¢çš„å…³é”®è¯åˆ—è¡¨
        references: ç´¯ç§¯çš„å‚è€ƒèµ„æ–™ {query: [results]}
        planning_rounds: å½“å‰è§„åˆ’è½®æ¬¡

        # å†…éƒ¨ä¾èµ–æ³¨å…¥ï¼ˆé€šè¿‡ config ä¼ å…¥ï¼Œä»¥ _ å¼€å¤´ï¼‰
        _embedding_service: Embedding æœåŠ¡å®ä¾‹
        _db_session: æ•°æ®åº“ä¼šè¯
        _conversation_id: ä¼šè¯ ID
    """

    messages: Annotated[list[AnyMessage], add_messages]
    mode: str

    # çŸ¥è¯†åº“ç›¸å…³
    knowledge_base_ids: list[int]
    history_context: str
    kb_context: str

    # DeepSearch ä¸“ç”¨å­—æ®µ
    question: str
    search_queries: list[str]
    references: dict[str, list[str]]
    planning_rounds: int

    # å†…éƒ¨ä¾èµ–æ³¨å…¥
    _embedding_service: Any
    _db_session: Any
    _conversation_id: int


# ========== 2. è·¯ç”±é€»è¾‘ ==========


def mode_router(state: AgentState) -> Literal["rewrite", "kb_precheck"]:
    """
    å…¥å£è·¯ç”±ï¼šæ ¹æ® mode å†³å®šè¿›å…¥æ™®é€šå¯¹è¯è¿˜æ˜¯æ·±åº¦æœç´¢ã€‚

    Chat Mode â†’ rewriteï¼ˆç„¶å context_retrievalï¼‰
    DeepSearch Mode â†’ kb_precheckï¼ˆç„¶å planningï¼‰
    """
    mode = state.get("mode", "chat")
    if mode == "deep_search":
        logger.info("ğŸ”¬ Entering DeepSearch mode")
        return "kb_precheck"
    else:
        logger.info("ğŸ’¬ Entering Chat mode")
        return "rewrite"


def tools_condition(state: AgentState) -> Literal["tools", "__end__"]:
    """
    æ¡ä»¶è·¯ç”±ï¼šå†³å®šä¸‹ä¸€æ­¥æ˜¯æ‰§è¡Œå·¥å…·è¿˜æ˜¯ç»“æŸã€‚
    """
    messages = state["messages"]
    last_message = messages[-1]

    if isinstance(last_message, AIMessage) and last_message.tool_calls:
        logger.info(f"ğŸ”§ Tool calls detected: {[tc['name'] for tc in last_message.tool_calls]}")
        return "tools"

    logger.debug("No tool calls, ending conversation")
    return "__end__"


def planning_router(state: AgentState) -> Literal["search", "summary"]:
    """
    DeepSearch è§„åˆ’è·¯ç”±ï¼šå†³å®šæ˜¯ç»§ç»­æœç´¢è¿˜æ˜¯è¿›å…¥æ€»ç»“ã€‚
    """
    from app.core.settings import get_settings

    settings = get_settings()
    max_rounds = settings.deep_search_max_rounds

    planning_rounds = state.get("planning_rounds", 0)
    search_queries = state.get("search_queries", [])

    # è¶…è¿‡æœ€å¤§è½®æ¬¡ï¼Œå¼ºåˆ¶è¿›å…¥æ€»ç»“
    if planning_rounds >= max_rounds:
        logger.warning(f"âš ï¸ Max planning rounds ({max_rounds}) reached, forcing summary")
        return "summary"

    # æœ‰æœç´¢è¯ï¼Œç»§ç»­æœç´¢
    if search_queries:
        logger.info(f"ğŸ” Search queries: {search_queries}")
        return "search"

    # æ— æœç´¢è¯ï¼Œè¿›å…¥æ€»ç»“
    logger.info("âœ… No more queries, proceeding to summary")
    return "summary"


# ========== 3. ä¸Šä¸‹æ–‡å¢å¼ºçš„ Chatbot èŠ‚ç‚¹ ==========


def create_context_aware_chatbot_node(model):
    """
    åˆ›å»ºä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ Chatbot èŠ‚ç‚¹

    è¯¥èŠ‚ç‚¹ä¼šå°† history_context å’Œ kb_context æ³¨å…¥åˆ°ç³»ç»Ÿæç¤ºä¸­ï¼Œ
    è®©æ¨¡å‹åœ¨å›ç­”æ—¶å‚è€ƒè¿™äº›ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

    Args:
        model: ç»‘å®šäº†å·¥å…·çš„ LangChain æ¨¡å‹å®ä¾‹

    Returns:
        èŠ‚ç‚¹å‡½æ•°
    """

    async def chatbot_node(state: dict[str, Any]) -> dict[str, list]:
        """
        ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„ Chatbot èŠ‚ç‚¹

        è¾“å…¥ state:
          - messages: æ¶ˆæ¯åˆ—è¡¨
          - history_context: å†å²å¯¹è¯ä¸Šä¸‹æ–‡
          - kb_context: çŸ¥è¯†åº“ä¸Šä¸‹æ–‡

        è¾“å‡º state:
          - messages: è¿½åŠ  AI å“åº”
        """
        messages = list(state.get("messages", []))
        history_context = state.get("history_context", "")
        kb_context = state.get("kb_context", "")

        logger.info(f"ğŸ¤– Context-aware Chatbot receiving {len(messages)} messages")
        logger.info(f"ğŸ“œ History context: {len(history_context)} chars")
        logger.info(f"ğŸ“š KB context: {len(kb_context)} chars")

        # æ„å»ºä¸Šä¸‹æ–‡å¢å¼ºçš„ç³»ç»Ÿæç¤º
        context_parts = []
        if kb_context:
            context_parts.append(kb_context)
        if history_context:
            context_parts.append(history_context)

        if context_parts:
            context_prompt = "\n\n".join(context_parts)
            # åœ¨æ¶ˆæ¯åˆ—è¡¨å¼€å¤´æ³¨å…¥ä¸Šä¸‹æ–‡ï¼ˆä½œä¸ºç³»ç»Ÿæ¶ˆæ¯çš„è¡¥å……ï¼‰
            # æŸ¥æ‰¾æ˜¯å¦å·²æœ‰ç³»ç»Ÿæ¶ˆæ¯
            has_system = any(
                isinstance(m, SystemMessage) and getattr(m, "id", None) == "sys_context"
                for m in messages
            )

            if not has_system:
                context_message = SystemMessage(
                    content=f"ä»¥ä¸‹æ˜¯ä¸ç”¨æˆ·é—®é¢˜ç›¸å…³çš„å‚è€ƒèµ„æ–™ï¼Œè¯·åœ¨å›ç­”æ—¶å‚è€ƒï¼š\n\n{context_prompt}",
                    id="sys_context",
                )
                # æ’å…¥åˆ°ç³»ç»ŸæŒ‡ä»¤ä¹‹å
                insert_idx = 0
                for i, m in enumerate(messages):
                    if isinstance(m, SystemMessage):
                        insert_idx = i + 1
                        break
                messages.insert(insert_idx, context_message)

        response = await model.ainvoke(messages)

        # è®°å½•å“åº”ä¿¡æ¯
        has_tool_calls = bool(response.tool_calls) if hasattr(response, "tool_calls") else False
        content_len = len(response.content) if response.content else 0
        logger.info(
            f"ğŸ¤– Chatbot response: has_tool_calls={has_tool_calls}, content_len={content_len}"
        )

        if has_tool_calls:
            logger.info(f"ğŸ”§ Tool calls: {[tc['name'] for tc in response.tool_calls]}")

        return {"messages": [response]}

    return chatbot_node


# ========== 4. æ„å»ºç»Ÿä¸€ Agent å›¾ ==========


def create_agent_graph(
    model: ChatOpenAI,
    tools: list[BaseTool],
    checkpointer=None,
    enable_rewrite: bool = True,
) -> StateGraph:
    """
    åˆ›å»º LangGraph Agent å·¥ä½œæµ (v4 - çŸ¥è¯†åº“é›†æˆ)ã€‚

    ç»Ÿä¸€å›¾æ¶æ„:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                           START                                  â”‚
    â”‚                             â”‚                                    â”‚
    â”‚                          router                                  â”‚
    â”‚                       â†™         â†˜                                â”‚
    â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”‚
    â”‚   â”‚    ğŸ’¬ Chat Mode       â”‚   â”‚   ğŸ”¬ DeepSearch       â”‚        â”‚
    â”‚   â”‚                       â”‚   â”‚                       â”‚        â”‚
    â”‚   â”‚  rewrite              â”‚   â”‚  kb_precheck          â”‚        â”‚
    â”‚   â”‚     â†“                 â”‚   â”‚     â†“                 â”‚        â”‚
    â”‚   â”‚  context_retrieval    â”‚   â”‚  planning â—„â”€â”€â”€â”€â”      â”‚        â”‚
    â”‚   â”‚  (history + kb)       â”‚   â”‚     â†“          â”‚      â”‚        â”‚
    â”‚   â”‚     â†“                 â”‚   â”‚  search? â”€â”€â”€â”€â”€â”€â”˜      â”‚        â”‚
    â”‚   â”‚  chatbot â—„â”€â”€â”€â”€â”       â”‚   â”‚     â†“                 â”‚        â”‚
    â”‚   â”‚     â†“         â”‚       â”‚   â”‚  summary              â”‚        â”‚
    â”‚   â”‚  tools? â”€â”€â”€â”€â”€â”€â”˜       â”‚   â”‚     â†“                 â”‚        â”‚
    â”‚   â”‚     â†“                 â”‚   â”‚    END                â”‚        â”‚
    â”‚   â”‚    END                â”‚   â”‚                       â”‚        â”‚
    â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    Args:
        model: LLM å®ä¾‹
        tools: å·¥å…·åˆ—è¡¨
        checkpointer: å¯é€‰çš„ checkpointer ç”¨äºçŠ¶æ€æŒä¹…åŒ–
        enable_rewrite: æ˜¯å¦å¯ç”¨ä»£è¯æ¶ˆè§£èŠ‚ç‚¹

    Returns:
        ç¼–è¯‘åçš„ CompiledStateGraph
    """
    from app.core.settings import get_settings

    settings = get_settings()

    # ç»‘å®šå·¥å…·åˆ°æ¨¡å‹
    if tools:
        logger.info(f"ğŸ”§ Binding {len(tools)} tools to model: {[t.name for t in tools]}")
        model_with_tools = model.bind_tools(tools)
    else:
        logger.warning("âš ï¸ No tools provided to agent")
        model_with_tools = model

    # åˆ›å»ºèŠ‚ç‚¹
    tool_node = ToolNode(tools) if tools else None
    rewrite_node = create_rewrite_node(model) if enable_rewrite else None
    context_node = create_context_node(settings)
    chatbot_node = create_context_aware_chatbot_node(model_with_tools)
    kb_precheck_node = create_kb_precheck_node(settings)
    planning_node = create_planning_node(model, settings)
    search_node = create_search_node(settings)
    summary_node = create_summary_node(model)

    # æ„å»ºçŠ¶æ€å›¾
    workflow = StateGraph(AgentState)

    # ===== æ·»åŠ æ‰€æœ‰èŠ‚ç‚¹ =====
    # å…¥å£è·¯ç”±èŠ‚ç‚¹
    workflow.add_node("router", lambda state: state)  # é€ä¼ èŠ‚ç‚¹

    # æ™®é€šå¯¹è¯åˆ†æ”¯
    if rewrite_node:
        workflow.add_node("rewrite", rewrite_node)
    workflow.add_node("context_retrieval", context_node)
    workflow.add_node("chatbot", chatbot_node)
    if tool_node:
        workflow.add_node("tools", tool_node)

    # DeepSearch åˆ†æ”¯
    workflow.add_node("kb_precheck", kb_precheck_node)
    workflow.add_node("planning", planning_node)
    workflow.add_node("search", search_node)
    workflow.add_node("summary", summary_node)

    # ===== å…¥å£è·¯ç”± =====
    workflow.set_entry_point("router")
    workflow.add_conditional_edges(
        "router",
        mode_router,
        {
            "rewrite": "rewrite" if rewrite_node else "context_retrieval",
            "kb_precheck": "kb_precheck",
        },
    )

    # ===== æ™®é€šå¯¹è¯åˆ†æ”¯è¾¹ =====
    if rewrite_node:
        workflow.add_edge("rewrite", "context_retrieval")

    workflow.add_edge("context_retrieval", "chatbot")

    if tool_node:
        workflow.add_conditional_edges(
            "chatbot",
            tools_condition,
            {
                "tools": "tools",
                "__end__": END,
            },
        )
        workflow.add_edge("tools", "chatbot")
    else:
        workflow.add_edge("chatbot", END)

    # ===== DeepSearch åˆ†æ”¯è¾¹ =====
    workflow.add_edge("kb_precheck", "planning")
    workflow.add_conditional_edges(
        "planning",
        planning_router,
        {
            "search": "search",
            "summary": "summary",
        },
    )
    workflow.add_edge("search", "planning")  # å¾ªç¯å›åˆ° planning
    workflow.add_edge("summary", END)

    # ç¼–è¯‘å¹¶è¿”å›
    return workflow.compile(checkpointer=checkpointer)


# ========== 5. ä¾¿æ·å·¥å‚å‡½æ•° ==========


def create_default_agent(
    model: ChatOpenAI,
    checkpointer=None,
    enable_rewrite: bool = True,
) -> StateGraph:
    """
    ä½¿ç”¨é»˜è®¤å·¥å…·é›†åˆ›å»º Agentã€‚

    åŒ…å«ï¼š
    - æ—¶é—´/è®¡ç®—å™¨å·¥å…·
    - RAG æ£€ç´¢å·¥å…·ï¼ˆå†å²å¯¹è¯æ£€ç´¢ï¼‰
    - Tavily æœç´¢å·¥å…·ï¼ˆå¦‚æœé…ç½®äº† API Keyï¼‰

    æ³¨æ„ï¼šçŸ¥è¯†åº“æ£€ç´¢å·²é›†æˆåˆ° context_retrieval èŠ‚ç‚¹ä¸­ï¼Œ
    ä¸å†ä½œä¸ºå·¥å…·ç”±æ¨¡å‹è‡ªä¸»è°ƒç”¨ï¼Œè€Œæ˜¯è‡ªåŠ¨æ‰§è¡Œã€‚
    """
    from app.core.settings import get_settings
    from app.tools import AVAILABLE_TOOLS
    from app.tools.rag_tool import rag_search
    from app.tools.tavily_tool import web_search

    settings = get_settings()

    # åŸºç¡€å·¥å…·
    all_tools = list(AVAILABLE_TOOLS)

    # æ·»åŠ  RAG å·¥å…·ï¼ˆå†å²å¯¹è¯æ£€ç´¢ï¼Œä½œä¸ºå¤‡ç”¨å·¥å…·ï¼‰
    all_tools.append(rag_search)

    # æ·»åŠ  Tavily æœç´¢å·¥å…·
    if settings.tavily_api_key:
        all_tools.append(web_search)

    return create_agent_graph(
        model=model,
        tools=all_tools,
        checkpointer=checkpointer,
        enable_rewrite=enable_rewrite,
    )
